{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T21:25:33.356934Z",
     "start_time": "2024-01-30T21:25:33.073062Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import logging\n",
    "from os import listdir, mkdir, system\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import sys\n",
    "import pathlib\n",
    "from tempfile import gettempdir\n",
    "import urllib\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyairtable import Table\n",
    "\n",
    "from Bio.Restriction import *\n",
    "from benchlingapi import Session\n",
    "\n",
    "import dnacauldron\n",
    "from geneblocks import CommonBlocks, load_record\n",
    "\n",
    "from Bio.Restriction import AllEnzymes\n",
    "from pydna.dseqrecord import Dseqrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('../synbiobot_CORE'):\n",
    "    sys.path.append('../synbiobot_CORE')\n",
    "\n",
    "from airtable_config import *\n",
    "from benchling_tools import benchling_to_gb, SeqFeature_to_BenchlingFeature, make_benchling_construct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console_handler = logging.StreamHandler()  # Console handler\n",
    "file_handler = logging.FileHandler('log.log')  # File handler\n",
    "\n",
    "# Configure the logging module\n",
    "logging.basicConfig(level=logging.INFO,  # Set logging level to INFO\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',  # Set log message format\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',  # Set date format for log messages\n",
    "                    handlers=[console_handler, file_handler])  # Log to both console and file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synbio gg_table\n",
    "api_key = os.getenv(\"AIRTABLE_API_KEY\")\n",
    "base_key=os.getenv(\"BASE_ID\")\n",
    "\n",
    "table_id = os.getenv(\"TABLE_GG_ID\")\n",
    "C_table_id = os.getenv(\"TABLE_C_ID\")\n",
    "benchling_api_key=os.getenv(\"BENCHLING_API_KEY\")\n",
    "\n",
    "if not all([api_key,base_key,table_id,C_table_id,benchling_api_key]):\n",
    "    raise ValueError(\"One or more env var is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T17:39:35.865354Z",
     "start_time": "2022-06-28T17:39:35.857555Z"
    }
   },
   "outputs": [],
   "source": [
    "Scan_result_field=\"Scan result\"\n",
    "Scan_product_field=\"Scan product\"\n",
    "Mols_OK_field='Molecules ðŸ‘Œ'\n",
    "Benchling_link_field='Benchling link (public)'\n",
    "Construct_name_descr_field='Construct name and description'\n",
    "Construct_to_assemble_field=\"Construct to assemble\"\n",
    "acceptor_field=\"Acceptor (C)\"\n",
    "acceptor_RE_field=\"RE (acceptor)\"\n",
    "other_molecules_field=\"Other molecules (C)\"\n",
    "other_mols_RE_field=\"RE (other molecules)\"\n",
    "create_C_tick_field=\"Create construct\"\n",
    "Mols_OK_suggested_field=\"ðŸ‘Œ mols suggested\"\n",
    "assembly_strategy_field=\"Assembly strategy\"\n",
    "backbone_field=\"backbone\"\n",
    "other_parents_field=\"other parents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepted MoClo enzymes\n",
    "MoClo_enzymes = [\"BpiI\",\"BbsI\",\"BsaI\",\"BsmBI\",\"SbfI\",\"AarI\",\"SapI\"]\n",
    "MoClo_enzymes_lower=[enz.lower() for enz in MoClo_enzymes]\n",
    "isosch_sep = \" = \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T17:39:39.495743Z",
     "start_time": "2022-06-28T17:39:39.486072Z"
    }
   },
   "outputs": [],
   "source": [
    "verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = pathlib.Path(gettempdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_GG_table= partial(get_table, table_id)\n",
    "get_C_table= partial(get_table, C_table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T17:39:39.501909Z",
     "start_time": "2022-06-28T17:39:39.497518Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace_double_space(s):\n",
    "    while \"  \" in s:\n",
    "        s=s.replace(\"  \",\" \")\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gg_record_is_complete(gg):\n",
    "    \"\"\"Checks if all the necessary info is provided in the gg record\"\"\"\n",
    "\n",
    "    error_msg=str()\n",
    "    gg_fields=gg.get(\"fields\")\n",
    "    \n",
    "    # check that exactly 1 acceptor was provided\n",
    "    if not len(gg_fields.get(acceptor_field,list()))==1:\n",
    "        error_msg=\"Please provide exactly one Acceptor\"\n",
    "\n",
    "    # check if some insert was provided\n",
    "    if not gg_fields.get(other_molecules_field) :\n",
    "        error_msg=\"Please provide at least one insert\"\n",
    "\n",
    "    # check if an enzyme was provided for the acceptor\n",
    "    if not gg_fields.get(acceptor_RE_field):\n",
    "        error_msg=f\"{acceptor_RE_field}: no enzyme!\"\n",
    "\n",
    "    # check if an enzyme was provided for the inserts\n",
    "    if not gg_fields.get(other_mols_RE_field):\n",
    "        error_msg=f\"{other_mols_RE_field}: no enzyme!\"\n",
    "\n",
    "    \n",
    "    # if all good\n",
    "    if not error_msg:\n",
    "        return(True)\n",
    "\n",
    "    # if something is missing\n",
    "    else:\n",
    "        gg_table.update(gg[\"id\"], {Scan_result_field: error_msg })\n",
    "        logging.error(error_msg)\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_sequence(construct_id, reaction_folder, gg):\n",
    "    \"\"\"Downloads a sequence.\"\"\"\n",
    "\n",
    "    gg_id = gg.get(\"id\")\n",
    "    \n",
    "    # Initialize file path as None\n",
    "    file_path = None\n",
    "\n",
    "    try:\n",
    "        # Fetch record\n",
    "        record = C_table.get(construct_id)\n",
    "        url = record.get(\"fields\").get(Benchling_link_field)\n",
    "        ID = record.get(\"fields\").get(\"ID\")\n",
    "        file_path = reaction_folder / f\"{ID}.gb\"\n",
    "\n",
    "        # Attempt to download the file\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url.split(\"?\")[0] + \".gb\", file_path)  # works with public links\n",
    "        except Exception as e:\n",
    "            benchling_to_gb(url, file_path)  # uses auth for non-public links\n",
    "\n",
    "    except:\n",
    "        error_msg = \"Could not fetch acceptor, try a public link\"\n",
    "        gg_table.update(gg_id, {Scan_result_field: error_msg})\n",
    "        logging.exception(error_msg)\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_directory(dir_path):\n",
    "    \"\"\"\n",
    "    Deletes the directory at the specified path if it exists, then recreates it.\n",
    "\n",
    "    Parameters:\n",
    "    dir_path (str): The path to the directory to be recreated.\n",
    "    \"\"\"\n",
    "    if os.path.exists(dir_path):\n",
    "        shutil.rmtree(dir_path)\n",
    "    os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gb(gb_path, gb_ID):\n",
    "    \"\"\"parse gb sequence file\"\"\"\n",
    "\n",
    "    if isinstance(gb_path,pathlib.Path):\n",
    "        gb_path=str(gb_path)\n",
    "    \n",
    "    try:\n",
    "        seqrec = dnacauldron.biotools.load_record(gb_path) # parse(acceptor_filename, ds=True)[0]\n",
    "        seqrec.id=gb_ID\n",
    "        seqrec.name=gb_ID\n",
    "        \n",
    "        if seqrec.annotations.get(\"topology\")==\"circular\":\n",
    "            seqrec = Dseqrecord(seqrec,circular=True,linear=False)\n",
    "        else:\n",
    "            seqrec = Dseqrecord(seqrec,circular=False,linear=True)\n",
    "\n",
    "        return(seqrec)\n",
    "            \n",
    "    except:\n",
    "        logging.exception(\"Could not parse gb file.\")\n",
    "\n",
    "        return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record_ID(table, record_id):\n",
    "    \"\"\"Returns the ID of the construct found in the constructs table\"\"\"\n",
    "    record_ID = table.get(record_id).get(\"fields\").get(\"ID\")\n",
    "    return(record_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enzyme_sort_out_isosch(enz):\n",
    "    \"\"\"If the selected enzyme contains the isoschizomere token, split and return the 1rst enzyme name\"\"\"\n",
    "    if isosch_sep in enz: \n",
    "        enz=enz.split(isosch_sep)[0]\n",
    "    return(enz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enzyme_is_supported(enz):\n",
    "    \"\"\"Checks if a selected enzyme is supported by this script.\n",
    "    Returns supported enzyme name if yes, False otherwise\"\"\"\n",
    "\n",
    "    enz=enzyme_sort_out_isosch(enz)\n",
    "    if enz.lower() not in MoClo_enzymes_lower:\n",
    "        return(False)\n",
    "\n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digest_keep_no_site(seqreq, enzyme_name):\n",
    "    \"\"\"Digests a Dseqrecord object using supplied enzyme, \n",
    "    returns the fragment that contains no recognition site if it is unique.\n",
    "    Returns False otherwise.\"\"\"\n",
    "\n",
    "    try:\n",
    "        enzyme = AllEnzymes.get(enzyme_name)\n",
    "        seqreq_dig = [elt for elt in seqreq.cut(enzyme) \\\n",
    "                      if len(enzyme.search(elt.seq))==0 \\\n",
    "                      and len(enzyme.search(elt.seq.reverse_complement()))==0]\n",
    "        \n",
    "        # we do not support more than one fragment to assemble per plasmid. But we totally could.\n",
    "        if len(seqreq_dig)==1:\n",
    "            return(seqreq_dig[0])\n",
    "        \n",
    "    except:\n",
    "        logging.exception(\"Could not digest fragment.\")\n",
    "    \n",
    "    return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recap_features(seqreq):\n",
    "    \"\"\"Returns a list of feature names (list of strings) from the provided seqreq record\"\"\"\n",
    "    \n",
    "    feature_names=list()\n",
    "    for feature in seqreq.features:\n",
    "        try:\n",
    "            name=feature.qualifiers[\"label\"]\n",
    "            if not name.startswith(\"Translation\") and not name.startswith(\"Intron\") and \"Linker\" not in name:\n",
    "                feature_names.append(name)\n",
    "        except:\n",
    "            logging.exception(\"Failed to summarise a feature name\")\n",
    "\n",
    "    return(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble(acceptor_dig, inserts_dig, gg):\n",
    "    \"\"\"Attempts assembly from digested acceptor and list of digested interts.\n",
    "    Return the assembly and an error message (empty if successful).\"\"\"\n",
    "\n",
    "    error_msg=str()\n",
    "    cloned=acceptor_dig\n",
    "    gg_ID = gg.get(\"fields\").get(\"ID\")\n",
    "    \n",
    "    try:\n",
    "        # while there are unassembled fragments and attempts left\n",
    "        tries = 50\n",
    "        while len(inserts_dig) and tries:\n",
    "            tries-=1\n",
    "            insert=inserts_dig.pop().reverse_complement()\n",
    "            try:\n",
    "                cloned=cloned+insert\n",
    "            except:\n",
    "                inserts_dig.insert(0,insert)\n",
    "\n",
    "        cloned.name=gg_ID\n",
    "        cloned.id=gg_ID\n",
    "        cloned=cloned.looped()\n",
    "\n",
    "    except Exception:\n",
    "        error_msg=\"Assembly failed\"\n",
    "        logging.exception(error_msg)\n",
    "        \n",
    "    if len(inserts_dig):\n",
    "        error_msg = \"Not all molecules used in assembly\"\n",
    "\n",
    "    return(cloned,error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_features(acceptor, inserts, cloned, gg):\n",
    "    \"\"\"Transfers the features found in acceptor and inserts to the assembled product.\n",
    "    Returns cloned, and an error message\n",
    "    \n",
    "    Note: eatures overlapping cutting sites get removed by dnacauldron, we add them back\n",
    "    Note: dnacauldron adds features to highlight the different parts that were assembled, we remove those\n",
    "    Note: we also remove duplicate features\n",
    "    Note: this functions will first remove all features, then add the ones we want.\n",
    "    \"\"\"\n",
    "\n",
    "    gg_ID = gg.get(\"fields\").get(\"ID\")\n",
    "\n",
    "    error_msg=str()\n",
    "    try:\n",
    "\n",
    "        # backup features\n",
    "        features_bkp = copy.deepcopy(cloned.features)\n",
    "        \n",
    "        # remove all features\n",
    "        cloned.features=[]\n",
    "        \n",
    "        # add acceptor features\n",
    "        blocks = CommonBlocks.from_sequences([acceptor, cloned])\n",
    "        new_records = blocks.copy_features_between_common_blocks(inplace=True)\n",
    "        cloned = new_records[gg_ID]\n",
    "        \n",
    "        # add insert features\n",
    "        for insert in inserts:\n",
    "\n",
    "            blocks = CommonBlocks.from_sequences([insert, cloned])\n",
    "            new_records = blocks.copy_features_between_common_blocks(inplace=True)\n",
    "            cloned = new_records[gg_ID] # not sure this is needed, as we are using inplace=True above\n",
    "\n",
    "        # remove duplicate features\n",
    "        signatures=list()\n",
    "        features_to_keep=list()\n",
    "        for feature in cloned.features:\n",
    "            signature = (feature.location, feature.qualifiers['label'])\n",
    "            if signature not in signatures:\n",
    "                signatures.append(signature)\n",
    "                features_to_keep.append(feature)\n",
    "\n",
    "        # assign features again\n",
    "        if features_to_keep:\n",
    "            cloned.features=features_to_keep\n",
    "        else:\n",
    "            cloned.features=features_bkp\n",
    "        \n",
    "    except Exception:\n",
    "        error_msg=\"Pass, but post-processing failed\"\n",
    "        logging.exception(error_msg)\n",
    "\n",
    "    return(cloned,error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recap_inserts_transferred_features(acceptor, inserts, cloned):\n",
    "    \"\"\"Returns a list of feature names (from the inserts) that were assembled into the product. Very basic implementation\"\"\"\n",
    "\n",
    "    feature_names_in_inserts = list()\n",
    "    for insert in inserts:\n",
    "        for feature in insert.features:\n",
    "            try:\n",
    "                feature_names_in_inserts.append(feature.qualifiers[\"label\"][0])\n",
    "            except:\n",
    "                logging.exception(\"Could not get feature name\")\n",
    "\n",
    "    feature_names_in_acceptor=list()\n",
    "    for feature in acceptor.features:\n",
    "        try:\n",
    "            feature_names_in_acceptor.append(feature.qualifiers[\"label\"][0])\n",
    "        except:\n",
    "            logging.exception(\"Could not get feature name\")\n",
    "        \n",
    "    feature_names=list()\n",
    "    for feature in cloned.features:\n",
    "        name = feature.qualifiers[\"label\"][0]\n",
    "        try:\n",
    "            if name in feature_names_in_inserts \\\n",
    "            and name not in feature_names_in_acceptor:\n",
    "                feature_names.append(name)\n",
    "        except:\n",
    "            logging.exception(\"Failed to summarise a feature name\")\n",
    "\n",
    "    return(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate pending reactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : dnacauldron docs provide example code for a simple/canonical GG example (with only 1 enzyme) but we often use 2 different enzymes, so we proceed step by step: first digest the constructs with their respective enzyme, then assemble the fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_reaction(gg):\n",
    "\n",
    "    \n",
    "    # prepare reaction -------------------------------------------------\n",
    "\n",
    "    # check if the gg record has all the required info\n",
    "    if not gg_record_is_complete(gg):\n",
    "        return\n",
    "\n",
    "    # get basic gg info\n",
    "    gg_id=gg.get('id')\n",
    "    gg_ID=get_record_ID(gg_table,gg_id)\n",
    "    gg_fields=gg.get(\"fields\")\n",
    "    \n",
    "    logging.info(f\"Simulating {gg_ID}\".center(50, \"-\"))\n",
    "\n",
    "    \n",
    "    # refresh reaction dir\n",
    "    reaction_path = working_dir/gg_ID\n",
    "    refresh_directory(reaction_path)\n",
    "\n",
    "    \n",
    "    # download sequences\n",
    "    logging.info(\"Download acceptor\")\n",
    "    acceptor_id = gg_fields.get(acceptor_field)[0]\n",
    "    acceptor_ID = get_record_ID(C_table,acceptor_id)\n",
    "    acceptor_path = download_sequence(acceptor_id, reaction_path, gg)\n",
    "\n",
    "    logging.info(\"Download other molecules\")\n",
    "    insert_ids = gg_fields.get(other_molecules_field)\n",
    "    insert_IDs = [get_record_ID(C_table, insert_id) for insert_id in insert_ids]\n",
    "    insert_paths=[download_sequence(insert_id, reaction_path, gg) \\\n",
    "                  for insert_id in gg_fields.get(other_molecules_field)]\n",
    "\n",
    "    \n",
    "    # check download success\n",
    "    error_msg=str()\n",
    "    if not acceptor_path:\n",
    "        error_msg=\"Could not fetch acceptor, try a public link\"\n",
    "        \n",
    "    if not all(insert_paths):\n",
    "        error_msg=\"Could not fetch insert, try a public link\"\n",
    "\n",
    "    if error_msg:\n",
    "        logging.error(error_msg)\n",
    "        gg_table.update(gg_id,{Scan_result_field:error_msg})\n",
    "        return\n",
    "\n",
    "    \n",
    "    # parse downloaded sequences\n",
    "    logging.info(\"Parse acceptor\")\n",
    "    acceptor = parse_gb(acceptor_path, acceptor_ID)\n",
    "    \n",
    "    logging.info(\"Parse inserts\")\n",
    "    inserts = [parse_gb(insert_path,gb_ID) for insert_path,gb_ID in zip(insert_paths,insert_IDs)]\n",
    "\n",
    "    error_msg=str()\n",
    "    if not acceptor:\n",
    "        error_msg=f\"Could not parse acceptor\"\n",
    "\n",
    "    if not all(inserts):\n",
    "        error_msg=f\"Could not parse insert(s)\"\n",
    "\n",
    "    if error_msg:\n",
    "        logging.error(error_msg)\n",
    "        gg_table.update(gg_id, {Scan_result_field: error_msg })\n",
    "        return\n",
    "\n",
    "    # check restriction enzymes\n",
    "    logging.info(\"Check restriction enzymes\")\n",
    "    acceptor_RE=gg_fields.get(acceptor_RE_field)\n",
    "    other_mols_RE=gg_fields.get(other_mols_RE_field)\n",
    "\n",
    "    error_msg=str()\n",
    "    if not enzyme_is_supported(acceptor_RE):\n",
    "        msg=f\"{acceptor_RE_field}: enzyme not supported\"\n",
    "    acceptor_RE = enzyme_sort_out_isosch(acceptor_RE)\n",
    "\n",
    "    if not enzyme_is_supported(other_mols_RE):\n",
    "        msg=f\"{other_mols_RE_field}: enzyme not supported\"\n",
    "    other_mols_RE = enzyme_sort_out_isosch(other_mols_RE)\n",
    "\n",
    "    if error_msg:\n",
    "        logging.error(error_msg)\n",
    "        gg_table.update(gg_id, {Scan_result_field: error_msg })\n",
    "        return\n",
    "\n",
    "        \n",
    "    # Digest fragments    \n",
    "    logging.info(\"Digesting acceptor\")\n",
    "    acceptor_dig = digest_keep_no_site(acceptor, acceptor_RE)\n",
    "    inserts_dig = [digest_keep_no_site(insert, other_mols_RE) for insert in inserts] \n",
    "    \n",
    "    error_msg=str()\n",
    "    if not acceptor_dig:\n",
    "        error_msg=\"Could not digest acceptor\" # maybe not the most accurate message\n",
    "    if not all(inserts_dig):\n",
    "        error_msg=\"Could not digest insert\"\n",
    "\n",
    "    if error_msg:\n",
    "        logging.error(error_msg)\n",
    "        gg_table.update(gg_id, {Scan_result_field: error_msg })\n",
    "        return        \n",
    "\n",
    "\n",
    "    # simulate assembly\n",
    "    logging.info(\"Simulate assembly\")\n",
    "    cloned, error_msg = assemble(acceptor_dig, inserts_dig, gg)\n",
    "    \n",
    "    if error_msg:\n",
    "        logging.error(error_msg)\n",
    "        gg_table.update(gg_id, {Scan_result_field: error_msg })\n",
    "        return\n",
    "    else:\n",
    "        msg=\"Pass\"\n",
    "        logging.info(msg)\n",
    "        gg_table.update(gg_id, {Scan_result_field: msg })\n",
    "\n",
    "    \n",
    "    # transfer features\n",
    "    logging.info(\"Adding features to assembled construct\")\n",
    "    cloned, error_msg = transfer_features(acceptor, inserts, cloned, gg)\n",
    "    if error_msg:\n",
    "        logging.error(error_msg)\n",
    "        gg_table.update(gg_id, {Scan_result_field:error_msg})\n",
    "        return\n",
    "\n",
    "\n",
    "    # add recap of suitable molecules\n",
    "    logging.info(\"Add suggested molecules\")\n",
    "    try:\n",
    "        msg=str()\n",
    "        for C_id in gg.get(\"fields\").get(acceptor_field)+ gg.get(\"fields\").get(other_molecules_field):\n",
    "            C_record = gg_table.get(C_id)\n",
    "            C_ID = C_record.get(\"fields\").get(\"ID\").strip()\n",
    "            C_mols_OK = C_record.get(\"fields\").get(Mols_OK_field,\"-\")\n",
    "            C_mols_OK = replace_double_space(C_mols_OK).strip().replace(' ',', ')\n",
    "            msg=f\"{msg}* __{C_ID}__: {C_mols_OK}\\n\"\n",
    "        gg_table.update(gg_id,{Mols_OK_suggested_field:msg})\n",
    "        \n",
    "    except:\n",
    "        error_msg=\"Pass, but failed to suggest suitable molecules\"\n",
    "        logging.exception(error_msg)\n",
    "        gg_table.update(gg_id, {Scan_result_field: error_msg })\n",
    "        return\n",
    "\n",
    "\n",
    "    # chekf if user wants to create a construct for the assembly\n",
    "    if not gg_fields.get(create_C_tick_field,False):\n",
    "        return\n",
    "\n",
    "    # create airtable record\n",
    "    logging.info(\"Create airtable record\")\n",
    "    try:\n",
    "\n",
    "        # create construct record in airtable\n",
    "        new_C = C_table.create({})\n",
    "        new_C_ID=new_C.get(\"fields\",{}).get(\"ID\")\n",
    "        logging.info(f\"Created new record {new_C_ID}\")\n",
    "        \n",
    "        # construct name\n",
    "        inserts_recap = recap_inserts_transferred_features(acceptor, inserts, cloned)\n",
    "        interts_recap = \", \".join(inserts_recap)\n",
    "        C_table.update(new_C.get(\"id\"),{Construct_name_descr_field:f\"ðŸ¤–ðŸ¤–ðŸ¤– {interts_recap} cloned into {acceptor_ID}\\n\"})\n",
    "        \n",
    "        # link gg to new construct\n",
    "        construct_list = gg.get(\"fields\").get(Construct_to_assemble_field,list())\n",
    "        construct_list.append(new_C[\"id\"])\n",
    "        gg_table.update(gg_id, {Construct_to_assemble_field: construct_list})\n",
    "        C_table.update(new_C.get(\"id\"),{assembly_strategy_field:f\"Product of {gg_ID}.\"})\n",
    "        \n",
    "        # backbone\n",
    "        C_table.update(new_C.get(\"id\"),{backbone_field:gg_fields.get(acceptor_field)})\n",
    "        \n",
    "        # other parts\n",
    "        C_table.update(new_C.get(\"id\"),{other_parents_field:gg_fields.get(other_molecules_field)})\n",
    "\n",
    "    except:\n",
    "        error_msg=\"Pass, but failed to create product record on Airtable\"\n",
    "        gg_table.update(gg_id, {Scan_result_field: error_msg })\n",
    "        logging.exception(error_msg)\n",
    "        return\n",
    "    \n",
    "    # save cloned product to benchling and store link in airtable\n",
    "    try:\n",
    "        cloned.features = [feature for feature in cloned.features if feature.qualifiers.get(\"label\",False)]\n",
    "        # SeqFeature_to_BenchlingFeature crashes if feature has not label\n",
    "        # only newly created features indicating parts have no label, so we can remove them\n",
    "        new_annots=[SeqFeature_to_BenchlingFeature(feature) for feature in cloned.features if feature.type!=\"primer_bind\"]\n",
    "        cloned_benchling = make_benchling_construct(name=new_C_ID,\n",
    "                                                    sequence=cloned.seq,\n",
    "                                                    annotations=new_annots,\n",
    "                                                    is_circular=True)\n",
    "\n",
    "        C_table.update(new_C.get(\"id\"),{Benchling_link_field: cloned_benchling.web_url})\n",
    "\n",
    "    except:\n",
    "        error_msg=\"Pass, but failed to save product on Benchling\"\n",
    "        gg_table.update(gg_id, {Scan_result_field: error_msg })\n",
    "        logging.exception(error_msg)\n",
    "        return\n",
    "\n",
    "    logging.info(\"Done\")\n",
    "    sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing=False\n",
    "\n",
    "if testing:\n",
    "    gg_table = get_GG_table()\n",
    "    C_table = get_C_table()\n",
    "    session = Session(benchling_api_key)\n",
    "    gg = gg_table.get(\"recjDUY3nwvshFS9N\")\n",
    "    simulate_reaction(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    while True:\n",
    "\n",
    "        try:\n",
    "            gg_table = get_GG_table()\n",
    "            C_table = get_C_table()\n",
    "            session = Session(benchling_api_key)\n",
    "            \n",
    "            reactions_to_simulate = gg_table.all()\n",
    "            reactions_to_simulate = [gg for gg in reactions_to_simulate \\\n",
    "                                     if gg.get(\"fields\").get(Scan_result_field)==\"Pending\"]\n",
    "        \n",
    "            for gg in reactions_to_simulate:\n",
    "                simulate_reaction(gg)\n",
    "                \n",
    "        except:\n",
    "            error_msg=\"Main GG loop failed\"\n",
    "            logging.exception(error_msg)\n",
    "\n",
    "        logging.info(\"Alive.\")\n",
    "        sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "820px",
    "left": "164px",
    "top": "111.963px",
    "width": "224.787px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "387px",
    "left": "1575px",
    "right": "20px",
    "top": "80px",
    "width": "273px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
